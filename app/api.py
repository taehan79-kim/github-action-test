from fastapi import APIRouter, HTTPException, File, UploadFile, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session
import os

from openai import OpenAI
from database import save_to_database, SessionLocal, DetectionResult
from models.house_model import detect_houses
from models.tree_model import detect_trees
from models.person_model import detect_people

# ë¶„ì„ í•¨ìˆ˜ ë§¤í•‘
from models.house_func import analyze_house
from models.person_func import analyze_person
from models.tree_func import analyze_tree

router = APIRouter()

# house label
house_label = {
    0: "ì§‘ì „ì²´",
    1: "ì§€ë¶•",
    2: "ì§‘ë²½",
    3: "ë¬¸",
    4: "ì°½ë¬¸",
    5: "êµ´ëš",
    6: "ì—°ê¸°",
    7: "ìš¸íƒ€ë¦¬",
    8: "ê¸¸",
    9: "ì—°ëª»",
    10: "ì‚°",
    11: "ë‚˜ë¬´",
    12: "ê½ƒ",
    13: "ì”ë””",
    14: "íƒœì–‘"
}

# person label
person_label = {
    0: "ì‚¬ëŒì „ì²´",
    1: "ë¨¸ë¦¬",
    2: "ì–¼êµ´",
    3: "ëˆˆ",
    4: "ì½”",
    5: "ì…",
    6: "ê·€",
    7: "ë¨¸ë¦¬ì¹´ë½",
    8: "ëª©",
    9: "ìƒì²´",
    10: "íŒ”",
    11: "ì†",
    12: "ë‹¤ë¦¬",
    13: "ë°œ",
    14: "ë‹¨ì¶”",
    15: "ì£¼ë¨¸ë‹ˆ",
    16: "ìš´ë™í™”",
    17: "êµ¬ë‘"
}

# tree label
tree_label = {
    0: "ë‚˜ë¬´ì „ì²´",
    1: "ê¸°ë‘¥",
    2: "ìˆ˜ê´€",
    3: "ê°€ì§€",
    4: "ë¿Œë¦¬",
    5: "ë‚˜ë­‡ì",
    6: "ê½ƒ",
    7: "ì—´ë§¤",
    8: "ê·¸ë„¤",
    9: "ìƒˆ",
    10: "ë‹¤ëŒì¥",
    11: "êµ¬ë¦„",
    12: "ë‹¬",
    13: "ë³„"
}

##############################
# 1) YOLO ê°ì²´ íƒì§€ ê´€ë ¨ ì½”ë“œ
##############################

class ImageRequest(BaseModel):
    """
    image_type: "house", "tree", ë˜ëŠ” "person"
    image_path: ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    image_type: str
    image_path: str

def parse_bboxes(yolo_raw_boxes, image_type):
    """
    YOLO ê²°ê³¼ê°’ì„ ë°›ì•„ (h, w, x, y) í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” í—¬í¼ í•¨ìˆ˜.
    YOLOëŠ” ì¼ë°˜ì ìœ¼ë¡œ [x1, y1, x2, y2, confidence, class_id] í˜•íƒœë¡œ ë°°ì—´ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •.
    """
    parsed = []
    for bbox in yolo_raw_boxes:
        # ì˜ˆ) bbox = [x1, y1, x2, y2, confidence, label]
        x1, y1, x2, y2 = bbox[:4]
        w = x2 - x1
        h = y2 - y1
        if image_type == "house":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": house_label[int(bbox[5])]
            })
        elif image_type == "person":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": person_label[int(bbox[5])]
            })
        elif image_type == "tree":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": tree_label[int(bbox[5])]
            })
    return parsed

@router.post("/detect")
async def detect_image(
    image: UploadFile = File(...),
    type: str = Form(...)
):
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        contents = await image.read()
        image_path = f"temp/{image.filename}"
        with open(image_path, "wb") as f:
            f.write(contents)
        
        try:
            formatted_boxes = []
            
            # ê°ì²´ ê°ì§€ ìˆ˜í–‰
            if type == "house":
                boxes = detect_houses(image_path)
                detect_func = analyze_house
                label_dict = house_label 
            elif type == "tree":
                boxes = detect_trees(image_path)
                detect_func = analyze_tree
                label_dict = tree_label
            elif type == "person":
                boxes = detect_people(image_path)
                detect_func = analyze_person
                label_dict = person_label
            else:
                return {"status": "error", "message": "Invalid type"}

            # boxes í˜•ì‹ ê²€ì¦ ë° ë³€í™˜
            if isinstance(boxes, list):
                formatted_boxes = [
                    {
                        "label": label_dict[int(box[5])],
                        "x": float(box[0]),
                        "y": float(box[1]),
                        "w": float(box[2] - box[0]),
                        "h": float(box[3] - box[1])
                    }
                    for box in boxes
                ]
                
                # YOLO ë¶„ì„
                yolo_analysis = detect_func(formatted_boxes)
                
                # GPT ë¶„ì„
                gpt_result = await analyze_drawing(image_path, formatted_boxes, type)
                
                # ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
                if gpt_result and "gpt_result" in gpt_result:
                    analysis_text = gpt_result["gpt_result"]
                else:
                    analysis_text = yolo_analysis if isinstance(yolo_analysis, str) else "\n".join(yolo_analysis)

            else:
                analysis_text = f"No {type} objects detected"

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(image_path):
                os.remove(image_path)

            return {
                "status": "success",
                "analysis": analysis_text,
                "boxes": formatted_boxes
            }

        except Exception as analysis_error:
            print(f"Analysis error: {str(analysis_error)}")
            if os.path.exists(image_path):
                os.remove(image_path)
            return {
                "status": "error",
                "message": "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(analysis_error)
            }
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return {"status": "error", "message": str(e)}

##############################
# 2) GPT ë¶„ì„ ê´€ë ¨ ì½”ë“œ
##############################
from dotenv import load_dotenv
load_dotenv() 

# OpenAI API í‚¤ ì„¤ì • ìˆ˜ì •
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

@router.get("/analysis/{image_path:path}")
async def analyze_drawing(image_path: str, boxes: list, type: str):
    """
    1) íƒì§€ ê²°ê³¼ ë¶„ì„
    2) GPT APIë¥¼ í†µí•´ HTP í•´ì„ í”„ë¡¬í”„íŠ¸ ì „ì†¡
    3) ê²°ê³¼ ë°˜í™˜
    """
    try:
        # íŠ¹ì§• ë¶„ì„
        feature_list = []
        
        # ê° íƒ€ì…ë³„ ë¶„ì„ ìˆ˜í–‰
        if type == "house":
            feature_list.extend(analyze_house(boxes))
        elif type == "tree":
            feature_list.extend(analyze_tree(boxes))
        elif type == "person":
            feature_list.extend(analyze_person(boxes))

        # GPTì— ì „ë‹¬í•  ë¬¸ìì—´ ìƒì„±
        features_str = "\n".join(feature_list)

        # system_prompt (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        system_prompt = """You are a professional HTP psychologist and mental health counselor.
        Analyze both current psychological state and developmental influences through drawing features.
        Provide detailed analysis by connecting specific drawing features to psychological interpretations. 
        - Use formal Korean (-ìŠµë‹ˆë‹¤)
        - Do not use special characters
        - Avoid using personal pronouns or labels (e.g., 'you', 'artist', etc)
        - Only use emojis that are specifically defined in section headers
        """

        # user_prompt (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        user_prompt = f"""
        === HTP Analysis Request ===
        Drawing Type: {type.upper()}
        Features Detected:
        {features_str}

        Using the bounding box coordinates [x,y,w,h], analyze the sketch and provide psychological interpretation in formal Korean.
        Translate all measurements into descriptive terms (e.g., centered, upper right, large, small):

        1. Personality Analysis:
        - Start with "1. ğŸ”… ì„±ê²© íŠ¹ì§• ğŸ”…"
        - Key personality traits
        - Analyze element sizes and placements from coordinates
        - Connect spatial features to personality traits
        - Interpret overall composition

        2. Social Characteristics:
        - Start with "2. ğŸŒ¤ï¸ ëŒ€ì¸ ê´€ê³„ ğŸŒ¤ï¸"
        - Family relationship patterns
        - Communication style
        - Interpret element spacing and relationship boundaries
        - Attachment patterns

        3. Current Mental State:
        - Start with "3. ğŸ§˜ í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœ ğŸ§˜"
        - Emotional stability
        - Developmental effects
        - Stress/anxiety levels
        - Coping mechanisms

        4. Mental Health Care:
        - Start with "4. ğŸ’ª ë©˜íƒˆ ì¼€ì–´ Tips ğŸ’ª"
        - Understanding past influences
        - Stress management suggestions
        - Provide practical suggestions
        - Growth potential
        """

        # (3-3) ìµœì‹  openai >= 1.0.0 ë°©ì‹
        # ChatCompletion â†’ "openai.chat_completions.create(...)"
        # ë˜ëŠ” ê·¸ëŒ€ë¡œ openai.ChatCompletion.create(...)ê°€ ë™ì‘í•˜ëŠ” ê²½ìš°ë„ ìˆìœ¼ë‚˜,
        # ìµœì‹  ê¶Œì¥ ë°©ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ê³µì‹ OpenAI ëª¨ë¸ ì‚¬ìš© (ex: gpt-3.5-turbo or gpt-4)
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5,
            max_tokens=1000,
            presence_penalty=0.3
        )

        gpt_answer = response.choices[0].message.content.strip()

        return {
            "status": "success",
            "features_analyzed": feature_list,
            "gpt_result": gpt_answer
        }

    except Exception as e:
        print(f"GPT Analysis error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))