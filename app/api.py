from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from sqlalchemy.orm import Session

from openai import OpenAI
from database import save_to_database, SessionLocal, DetectionResult
from models.house_model import detect_houses
from models.tree_model import detect_trees
from models.person_model import detect_people

# ë¶„ì„ í•¨ìˆ˜ ë§¤í•‘
from models.house_func import analyze_house
from models.person_func import analyze_person
from models.tree_func import analyze_tree

router = APIRouter()

# house label
house_label = {
    0: "ì§‘ì „ì²´",
    1: "ì§€ë¶•",
    2: "ì§‘ë²½",
    3: "ë¬¸",
    4: "ì°½ë¬¸",
    5: "êµ´ëš",
    6: "ì—°ê¸°",
    7: "ìš¸íƒ€ë¦¬",
    8: "ê¸¸",
    9: "ì—°ëª»",
    10: "ì‚°",
    11: "ë‚˜ë¬´",
    12: "ê½ƒ",
    13: "ì”ë””",
    14: "íƒœì–‘"
}

# person label
person_label = {
    0: "ì‚¬ëŒì „ì²´",
    1: "ë¨¸ë¦¬",
    2: "ì–¼êµ´",
    3: "ëˆˆ",
    4: "ì½”",
    5: "ì…",
    6: "ê·€",
    7: "ë¨¸ë¦¬ì¹´ë½",
    8: "ëª©",
    9: "ìƒì²´",
    10: "íŒ”",
    11: "ì†",
    12: "ë‹¤ë¦¬",
    13: "ë°œ",
    14: "ë‹¨ì¶”",
    15: "ì£¼ë¨¸ë‹ˆ",
    16: "ìš´ë™í™”",
    17: "ë‚¨ìêµ¬ë‘"
}

# tree label
tree_label = {
    0: "ë‚˜ë¬´ì „ì²´",
    1: "ê¸°ë‘¥",
    2: "ìˆ˜ê´€",
    3: "ê°€ì§€",
    4: "ë¿Œë¦¬",
    5: "ë‚˜ë­‡ì",
    6: "ê½ƒ",
    7: "ì—´ë§¤",
    8: "ê·¸ë„¤",
    9: "ìƒˆ",
    10: "ë‹¤ëŒì¥",
    11: "êµ¬ë¦„",
    12: "ë‹¬",
    13: "ë³„"
}

##############################
# 1) YOLO ê°ì²´ íƒì§€ ê´€ë ¨ ì½”ë“œ
##############################

class ImageRequest(BaseModel):
    """
    image_type: "house", "tree", ë˜ëŠ” "person"
    image_path: ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    image_type: str
    image_path: str

def parse_bboxes(yolo_raw_boxes, image_type):
    """
    YOLO ê²°ê³¼ê°’ì„ ë°›ì•„ (h, w, x, y) í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” í—¬í¼ í•¨ìˆ˜.
    YOLOëŠ” ì¼ë°˜ì ìœ¼ë¡œ [x1, y1, x2, y2, confidence, class_id] í˜•íƒœë¡œ ë°°ì—´ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •.
    """
    parsed = []
    for bbox in yolo_raw_boxes:
        # ì˜ˆ) bbox = [x1, y1, x2, y2, confidence, label]
        x1, y1, x2, y2 = bbox[:4]
        w = x2 - x1
        h = y2 - y1
        if image_type == "house":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": house_label[int(bbox[5])]
            })
        elif image_type == "person":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": person_label[int(bbox[5])]
            })
        elif image_type == "tree":
            parsed.append({
                "x": float(x1),
                "y": float(y1),
                "w": float(w),
                "h": float(h),
                "confidence": float(bbox[4]),
                "label": tree_labe[int(bbox[5])]
            })
    return parsed

@router.post("/detect")
async def detect_objects(request: ImageRequest):
    """
    1) image_typeì„ ë³´ê³  í•´ë‹¹ YOLO ëª¨ë¸ ì‚¬ìš© (house/tree/person)
    2) íƒì§€ ê²°ê³¼ì˜ bboxë¥¼ (h, w, x, y) í˜•íƒœë¡œ íŒŒì‹±
    3) DBì— ì €ì¥
    4) ê²°ê³¼ë¥¼ ë°˜í™˜
    """
    try:
        image_type = request.image_type.lower()
        image_path = request.image_path

        if image_type == "house":
            raw_results = detect_houses(image_path)
            parsed_results = parse_bboxes(raw_results, image_type)
        elif image_type == "tree":
            raw_results = detect_trees(image_path)
            parsed_results = parse_bboxes(raw_results, image_type)
        elif image_type == "person":
            raw_results = detect_people(image_path)
            parsed_results = parse_bboxes(raw_results, image_type)
        else:
            raise ValueError("image_typeì€ house, tree, person ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        detection_data = { image_type: parsed_results }

        save_to_database(image_path, detection_data)

        return {
            "status": "success",
            "image_path": image_path,
            "results": detection_data
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


##############################
# 2) GPT ë¶„ì„ ê´€ë ¨ ì½”ë“œ
##############################

# (1) OpenAI API í‚¤ ì„¤ì • (ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œ ë³´ì•ˆì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
api_key = "your_api_key"
client = OpenAI(api_key=api_key)

@router.get("/analysis/{image_path:path}")
async def analyze_image(image_path: str):
    """
    1) DBì—ì„œ image_pathì— í•´ë‹¹í•˜ëŠ” íƒì§€ ê²°ê³¼ ì¡°íšŒ
    2) íƒì§€ ê²°ê³¼(ì˜ˆ: house, tree, person ê°ê°ì˜ bbox) ë¶„ì„: ë°”ìš´ë”© ë°•ìŠ¤ ë©´ì ì´ í°ì§€ ì‘ì€ì§€ ë“±
    3) GPT APIë¥¼ í†µí•´ HTP í•´ì„ í”„ë¡¬í”„íŠ¸ ì „ì†¡
    4) ê²°ê³¼ ë°˜í™˜
    """
    try:
        # 1) DBì—ì„œ ê²°ê³¼ ì¡°íšŒ
        session = SessionLocal()
        db_entry = session.query(DetectionResult).filter_by(image_path=image_path).first()
        session.close()

        if not db_entry:
            raise HTTPException(status_code=404, detail=f"í•´ë‹¹ {image_path}ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")

        detection_data = db_entry.results

        # 2) 'í¬ë‹¤/ì‘ë‹¤' ê°„ë‹¨ ë¶„ì„
        feature_list = []

        for cls_name, bboxes in detection_data.items():
            if cls_name == "house":
                # House ë¶„ì„
                house_results = analyze_house(bboxes)  # bboxesëŠ” DBì—ì„œ ê°€ì ¸ì˜¨ ë°”ìš´ë”© ë°•ìŠ¤ ë°ì´í„°
                feature_list.extend(house_results)

            elif cls_name == "person":
                # Person ë¶„ì„
                person_results = analyze_person(bboxes)  # bboxes ì „ë‹¬
                feature_list.extend(person_results)

            elif cls_name == "tree":
                # Tree ë¶„ì„
                tree_results = analyze_tree(bboxes)  # bboxes ì „ë‹¬
                feature_list.extend(tree_results)

        # GPTì— ì „ë‹¬í•  ë¬¸ìì—´ ìƒì„±
        features_str = "\n".join(feature_list)

        # (3-1) system_prompt
        system_prompt = """You are a professional HTP psychologist and mental health counselor.
        Analyze both current psychological state and developmental influences through drawing features.
        Provide detailed analysis by connecting specific drawing features to psychological interpretations. 
        - Use formal Korean (-ìŠµë‹ˆë‹¤)
        - Do not use special characters
        - Avoid using personal pronouns or labels (e.g., 'you', 'artist', etc)
        - Only use emojis that are specifically defined in section headers
        """

        # (3-2) user_prompt
        # ì´ë¯¸ì§€ ê²½ë¡œì— "house", "tree", "person" ë¬¸ìì—´ì´ í¬í•¨ë˜ë©´ ê·¸ê±¸ë¡œ drawing_typeì„ ê²°ì •
        drawing_type = "HTP"
        lower_path = image_path.lower()
        if "house" in lower_path:
            drawing_type = "house"
        elif "tree" in lower_path:
            drawing_type = "tree"
        elif "person" in lower_path:
            drawing_type = "person"

        user_prompt = f"""
        === HTP Analysis Request ===
        Drawing Type: {drawing_type.upper()}
        Features Detected:
        {features_str}

        Using the bounding box coordinates [x,y,w,h], analyze the sketch and provide psychological interpretation in formal Korean.
        Translate all measurements into descriptive terms (e.g., centered, upper right, large, small):

        1. Personality Analysis:
        - Start with "1. ğŸ”… ì„±ê²© íŠ¹ì§• ğŸ”…"
        - Key personality traits
        - Analyze element sizes and placements from coordinates
        - Connect spatial features to personality traits
        - Interpret overall composition

        2. Social Characteristics:
        - Start with "2. ğŸŒ¤ï¸ ëŒ€ì¸ ê´€ê³„ ğŸŒ¤ï¸"
        - Family relationship patterns
        - Communication style
        - Interpret element spacing and relationship boundaries
        - Attachment patterns

        3. Current Mental State:
        - Start with "3. ğŸ§˜ í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœ ğŸ§˜"
        - Emotional stability
        - Developmental effects
        - Stress/anxiety levels
        - Coping mechanisms

        4. Mental Health Care:
        - Start with "4. ğŸ’ª ë©˜íƒˆ ì¼€ì–´ Tips ğŸ’ª"
        - Understanding past influences
        - Stress management suggestions
        - Provide practical suggestions
        - Growth potential

        Analysis guidelines:
        - Start content immediately after each section title
        - Write clear and concise paragraphs
        - Translate coordinates into descriptive terms
        - Include practical advice
        - Maintain a supportive tone
        """

        # (3-3) ìµœì‹  openai >= 1.0.0 ë°©ì‹
        # ChatCompletion â†’ "openai.chat_completions.create(...)"
        # ë˜ëŠ” ê·¸ëŒ€ë¡œ openai.ChatCompletion.create(...)ê°€ ë™ì‘í•˜ëŠ” ê²½ìš°ë„ ìˆìœ¼ë‚˜,
        # ìµœì‹  ê¶Œì¥ ë°©ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ê³µì‹ OpenAI ëª¨ë¸ ì‚¬ìš© (ex: gpt-3.5-turbo or gpt-4)
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5,
            max_tokens=1000,
            presence_penalty=0.3
        )

        gpt_answer = response.choices[0].message.content.strip()

        # 4) ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "status": "success",
            "features_analyzed": feature_list,
            "gpt_result": gpt_answer
        }

    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))